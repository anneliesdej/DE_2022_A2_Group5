{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dfdcbb6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ParentLocation: string (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- Period: long (nullable = true)\n",
      " |-- isLatestYear: string (nullable = true)\n",
      " |-- Dim1: string (nullable = true)\n",
      " |-- FactValueNumeric: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql.types import StructType, StructField, StringType, LongType, DoubleType, DateType\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "#set up spark (session)\n",
    "sparkConf = SparkConf()\n",
    "sparkConf.setMaster(\"spark://spark-master:7077\")\n",
    "sparkConf.setAppName(\"BatchPipeline\")\n",
    "sparkConf.set(\"spark.driver.memory\", \"2g\")\n",
    "sparkConf.set(\"spark.executor.cores\", \"1\")\n",
    "sparkConf.set(\"spark.driver.cores\", \"1\")\n",
    "\n",
    "spark = SparkSession.builder.config(conf=sparkConf).getOrCreate()\n",
    "\n",
    "#set up hadoop fs configuration\n",
    "conf = spark.sparkContext._jsc.hadoopConfiguration()\n",
    "conf.set(\"fs.gs.impl\", \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem\")\n",
    "conf.set(\"fs.AbstractFileSystem.gs.impl\", \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS\")\n",
    "\n",
    "#retrieve data from bucket\n",
    "#google storage file path\n",
    "#make sure this is a separate bucket that only has the correct files in there\n",
    "gsc_file_path = 'gs://de_jads_batch_data2/' # bucket name with whodata.csv file\n",
    "\n",
    "dataSchema = StructType(\n",
    "    [StructField(\"ParentLocation\", StringType(), True),\n",
    "    StructField(\"Location\", StringType(), True),\n",
    "    StructField(\"Period\", LongType(), True),\n",
    "    StructField(\"isLatestYear\", StringType(), True),\n",
    "    StructField(\"Dim1\", StringType(), True),\n",
    "    StructField(\"FactValueNumeric\", DoubleType(), True)\n",
    "    ])\n",
    "\n",
    "consumed_import = spark.read.format(\"csv\").schema(dataSchema).option(\"header\", \"true\") \\\n",
    "    .load(gsc_file_path+'whodata.csv')\n",
    "\n",
    "consumed_import.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "739a21a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+--------------+\n",
      "|             Country|Year|Litres_alcohol|\n",
      "+--------------------+----+--------------+\n",
      "|United States of ...|1960|          7.83|\n",
      "|             Austria|1960|          8.91|\n",
      "|         Afghanistan|1961|           0.0|\n",
      "|              Guinea|1961|          0.24|\n",
      "|Micronesia (Feder...|1961|           0.0|\n",
      "|                Oman|1961|           0.0|\n",
      "|          Bangladesh|1961|           0.0|\n",
      "|              Kuwait|1961|          0.02|\n",
      "|               Nepal|1961|           0.0|\n",
      "|          Mauritania|1961|          0.11|\n",
      "|               Qatar|1961|           0.0|\n",
      "|        Saudi Arabia|1961|           0.0|\n",
      "|            Pakistan|1961|          0.01|\n",
      "|           Indonesia|1961|          0.03|\n",
      "|              Malawi|1961|          0.05|\n",
      "|             Somalia|1961|          0.06|\n",
      "|             Comoros|1961|          0.12|\n",
      "|               Niger|1961|          0.13|\n",
      "|Iran (Islamic Rep...|1961|          0.14|\n",
      "|              Jordan|1961|          0.14|\n",
      "+--------------------+----+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "consumed = consumed_import.select(col('Location').alias('Country') , col('Period').alias('Year'), col('FactValueNumeric').alias('Litres_alcohol')) \\\n",
    "    .where(col('Dim1') == 'All types')\\\n",
    "    .sort('Year') \\\n",
    "\n",
    "consumed.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95ebe83b-b6ad-4190-8d5e-e61e1f59c96e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+---------+\n",
      "|Year|    Litres_alcohol|  Country|\n",
      "+----+------------------+---------+\n",
      "|1960| 8.370000000000001|Worldwide|\n",
      "|1961|3.7132867132867133|Worldwide|\n",
      "|1962| 3.817260273972604|Worldwide|\n",
      "|1963|3.9981045751633966|Worldwide|\n",
      "|1964| 4.081307189542484|Worldwide|\n",
      "|1965|4.1433333333333335|Worldwide|\n",
      "|1966| 4.286233766233765|Worldwide|\n",
      "|1967| 4.313701298701301|Worldwide|\n",
      "|1968| 4.387272727272727|Worldwide|\n",
      "|1969| 4.461233766233767|Worldwide|\n",
      "|1970| 4.644774193548388|Worldwide|\n",
      "|1971| 4.726129032258064|Worldwide|\n",
      "|1972| 4.818774193548387|Worldwide|\n",
      "|1973| 5.024935897435899|Worldwide|\n",
      "|1974| 5.041730769230769|Worldwide|\n",
      "|1975|  5.10294871794872|Worldwide|\n",
      "|1976| 5.168701298701301|Worldwide|\n",
      "|1977| 5.180064516129034|Worldwide|\n",
      "|1978| 5.149350649350646|Worldwide|\n",
      "|1979| 5.139032258064514|Worldwide|\n",
      "+----+------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "yearly_ww_consumed = consumed.select('Year', 'Litres_alcohol') \\\n",
    "    .groupBy('Year') \\\n",
    "    .agg(avg('Litres_alcohol').alias('Litres_alcohol')) \\\n",
    "    .withColumn(\"Country\", lit(\"Worldwide\"))\n",
    "\n",
    "yearly_ww_consumed.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9a7bb13-97bb-4d50-83a0-d70fa2ecb5da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+-----------------+\n",
      "|Year|             Country|   Litres_alcohol|\n",
      "+----+--------------------+-----------------+\n",
      "|1960|United States of ...|             7.83|\n",
      "|1960|           Worldwide|8.370000000000001|\n",
      "|1960|             Austria|             8.91|\n",
      "|1961|         Afghanistan|              0.0|\n",
      "|1961|          Bangladesh|              0.0|\n",
      "|1961|Micronesia (Feder...|              0.0|\n",
      "|1961|               Nepal|              0.0|\n",
      "|1961|                Oman|              0.0|\n",
      "|1961|               Qatar|              0.0|\n",
      "|1961|        Saudi Arabia|              0.0|\n",
      "+----+--------------------+-----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joinExpression = [\"Year\", \"Country\", \"Litres_alcohol\"]\n",
    "consumption = consumed.join(yearly_ww_consumed, joinExpression, \"full\")\n",
    "\n",
    "consumption.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3c6670f-79b9-40f3-9e61-9a79266356e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write data to bucket\n",
    "consumption.write.mode(\"overwrite\").format(\"csv\").save(\"gs://jadsdenb/consumed\") # bucket name !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9869848a-dc5a-4341-b793-0781d6caf522",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use the cloud storage bucket for temporary BigQuery export data used by the connector\n",
    "bucket = \"de_jads_temp_annelies\" # bucket name !\n",
    "spark.conf.set('temporaryGcsBucket', bucket)\n",
    "\n",
    "#save the combined matches data to BigQuery -> do not forget to change project ID\n",
    "consumption.write.format('bigquery') \\\n",
    "    .option('table', 'de2022-362620.assignment2dataset.consumption') \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6fb91eed-6056-4065-aa0b-7562be42d014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop the spark context\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fceda38-8383-4d64-a2a6-62bf6f75aac1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
